{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07: Merging and Joining Data\n",
    "\n",
    "This lab is presented with some revisions from [Dennis Sun at Cal Poly](https://web.calpoly.edu/~dsun09/index.html) and his [Data301 Course](http://users.csc.calpoly.edu/~dsun09/data301/lectures.html)\n",
    "\n",
    "### When you have filled out all the questions, submit via [Tulane Canvas](https://tulane.instructure.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situtions, the information you need is spread across multiple data sets, so you will need to combine multiple data sets into one. In this chapter, we explore how to combine information from multiple (tabular) data sets.\n",
    "\n",
    "As a working example, we will use the baby names data collected by the Social Security Administration. Each data set in this collection contains the names of all babies born in the United States in a particular year. This data is [publicly available](https://www.ssa.gov/OACT/babynames/limits.html), and a copy has been made available at `./data/names/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNationalReadMe.pdf\u001b[m\u001b[m \u001b[1m\u001b[31myob1914.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1949.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1984.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1880.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1915.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1950.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1985.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1881.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1916.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1951.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1986.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1882.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1917.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1952.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1987.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1883.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1918.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1953.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1988.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1884.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1919.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1954.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1989.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1885.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1920.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1955.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1990.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1886.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1921.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1956.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1991.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1887.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1922.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1957.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1992.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1888.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1923.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1958.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1993.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1889.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1924.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1959.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1994.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1890.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1925.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1960.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1995.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1891.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1926.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1961.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1996.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1892.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1927.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1962.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1997.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1893.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1928.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1963.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1998.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1894.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1929.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1964.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1999.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1895.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1930.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1965.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2000.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1896.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1931.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1966.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2001.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1897.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1932.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1967.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2002.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1898.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1933.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1968.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2003.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1899.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1934.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1969.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2004.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1900.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1935.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1970.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2005.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1901.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1936.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1971.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2006.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1902.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1937.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1972.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2007.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1903.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1938.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1973.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2008.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1904.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1939.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1974.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2009.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1905.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1940.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1975.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2010.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1906.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1941.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1976.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2011.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1907.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1942.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1977.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2012.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1908.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1943.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1978.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2013.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1909.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1944.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1979.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2014.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1910.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1945.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1980.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2015.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1911.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1946.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1981.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2016.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1912.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1947.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1982.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2017.txt\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[31myob1913.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1948.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob1983.txt\u001b[m\u001b[m        \u001b[1m\u001b[31myob2018.txt\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this data is broken up into a lot of individual files, but if we want to use any of our `groupby` and other analysis techniques we need to make it into one file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "\n",
    "Sometimes, the _rows_ of data are spread across multiple files, and we want to combine the rows into a single data set. The process of combining rows from different data sets is known as **concatenation**. Visually, to concatenate two or more `DataFrame`s means to stack them on top of one another.\n",
    "\n",
    "<img src=\"./images/concatenate.png\" width=\"400\">\n",
    "\n",
    "For example, suppose we want to understand how the popularity of different names evolved between 1995 and 2015. The 1995 names and the 2015 names are stored in two different files: `yob1995.txt` and `yob2015.txt`, respectively. To carry out this analysis, we will need to combine these two data sets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# These two things are for Pandas, \n",
    "#it widens the notebook and lets us display data easily.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# Show a ludicrus number of rows and columns\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.width = 1000\n",
    "\n",
    "names1995 = pd.read_csv(\"./data/names/yob1995.txt\",\n",
    "                        header=None,\n",
    "                        names=[\"Name\", \"Sex\", \"Count\"])\n",
    "names1995.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names2015 = pd.read_csv(\"./data/names/yob2015.txt\",\n",
    "                        header=None,\n",
    "                        names=[\"Name\", \"Sex\", \"Count\"])\n",
    "names2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To concatenate the two, we use the `pd.concat()` function, which accepts a _list_ of `pandas` objects (`DataFrames` or `Series`) and concatenates them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([names1995, names2015])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems with the combined data set above. First, there is no longer any way to distinguish the 1995 data from the 2015 data. To fix this, we can add a \"Year\" column to each `DataFrame` before we concatenate. Second, the indexes from the individual `DataFrame`s have been preserved. (To see this, observe that the last index in the `DataFrame` is 32,951, which corresponds to the number of rows in `names2015`, but there are actually 59,032 rows in the `DataFrame`.) That means that there are two rows with an index of 0, two rows with an index of 1, and so on. To force `pandas` to create a completely new index for this `DataFrame`, ignoring the indices from the individual `DataFrame`s, we specify `ignore_index=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1995[\"Year\"] = 1995\n",
    "names2015[\"Year\"] = 2015\n",
    "names = pd.concat([names1995, names2015], ignore_index=True)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a `DataFrame` that we can use!\n",
    "\n",
    "Notice that the data is currently in tabular form, with one row per combination of name, sex, and year. It makes sense to set these to be the index of our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.set_index([\"Name\", \"Sex\", \"Year\"], inplace=True)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to show the counts for the two years side by side. In other words, we want a data cube with (name, sex) along one axis and year along the other. To do this, we can `.unstack()` the year from the index.  Note this is similar to a reverse Melt operation that we talked about in class -- a more tidy data way to do this may be to setup year as a multi index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.unstack(\"Year\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NaN`s simply indicate that there were no children (more precisely, if you read [the documentation](https://www.ssa.gov/OACT/babynames/limits.html), fewer than five children) born in the United States in that year. In this case, it makes sense to fill these `NaN` values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.unstack().fillna(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging (a.k.a. Joining)\n",
    "\n",
    "More commonly, the data sets that we want to combine actually contain different information about the same observations. In other words, instead of stacking the `DataFrame`s on top of each other, as in concatenation, we want to stack them next to each other. The process of combining columns or variables from different data sets is known as **merging** or **joining**.\n",
    "\n",
    "<img src=\"./images/merge.png\" width=\"400\">\n",
    "\n",
    "The observations in the two data sets may not be in the same order, so merging is not as simple as stacking the `DataFrame`s side by side. For example, the process might look as follows:\n",
    "\n",
    "![](./images/one-to-one.png)\n",
    "\n",
    "In _pandas_, merging is accomplished using the `.merge()` function. We have to specify the variable(s) that we want to match across the two data sets. For example, to merge the 1995 names with the 2015 names, we have to join on name and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1995.merge(names2015, on=[\"Name\", \"Sex\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables `Name` and `Sex` that we joined on each appear once in the resulting `DataFrame`. The variable `Count`, which we did not join on, appears twice---since there are columns called `Count` in both `DataFrame`s. Notice that `pandas` automatically appended the suffix `_x` to the name of the variable from the left data set and `_y` to the name from the right. We can customize the suffixes by specifying the `suffixes=` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1995.merge(names2015, on=[\"Name\", \"Sex\"], suffixes=(\"1995\", \"2015\")).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we assumed that the columns that we joined on had the same names in the two data sets. What if they had different names? For example, suppose the columns had been lowercase in one and uppercase in the other. We can specify which variables to use from the left and right data sets using the `left_on=` and `right_on=` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrames where the column names are different\n",
    "names1995_lower = names1995.copy()\n",
    "names2015_upper = names2015.copy()\n",
    "names1995_lower.columns = names1995.columns.str.lower()\n",
    "names2015_upper.columns = names2015.columns.str.upper()\n",
    "\n",
    "# This is how you merge them.\n",
    "names1995_lower.merge(\n",
    "    names2015_upper,\n",
    "    left_on=(\"name\", \"sex\"),\n",
    "    right_on=(\"NAME\", \"SEX\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we've managed to get some redundant columns so we would need to drop these to keep our data tidy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the \"variables\" that we want to join on are in the index? We can always call `.reset_index()` to make them columns, but we can also specify the arguments `left_index=True` or `right_index=True` to force `pandas` to use the index instead of columns.  Note that if we were to use the Pandas `join` command the default action would be to join on the indicies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1995_idx = names1995.set_index([\"Name\", \"Sex\"])\n",
    "names1995_idx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1995_idx.merge(names2015, left_index=True, right_on=(\"Name\", \"Sex\")).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this worked because the left `DataFrame` had an index with two levels, which were joined to two columns from the right `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-One and Many-to-One Relationships\n",
    "\n",
    "In the example above, there was at most one (name, sex) combination in the 2015 data set for each (name, sex) combination in the 1995 data set. These two data sets are thus said to have a **one-to-one relationship**. Another example of a one-to-one data set is the Beatles example from above. Each Beatle appears in each data set exactly once, so the name is uniquely identifying.\n",
    "\n",
    "![](./images/one-to-one.png)\n",
    "\n",
    "However, two data sets need not have a one-to-one relationship. For example, a data set that specifies the instrument(s) that each Beatle played would potentially feature each Beatle multiple times (if they played multiple instruments). If we joined this data set to the \"Beatles career\" data set, then each row in the \"Beatles career\" data set would be mapped to several rows in the \"instruments\" data set. These two data sets are said to have a **many-to-one relationship**.\n",
    "\n",
    "![](./images/many-to-one.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-Many Relationships: A Cautionary Tale\n",
    "\n",
    "In the baby names data, the name is not uniquely identifying. For example, there are both males and females with the name \"Jessie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jessie1995 = names1995[names1995[\"Name\"] == \"Jessie\"]\n",
    "jessie2015 = names2015[names2015[\"Name\"] == \"Jessie\"]\n",
    "\n",
    "jessie1995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is why we have to be sure to join on both name and sex. But what would go wrong if we joined these two `DataFrame`s on just \"Name\"? Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jessie1995.merge(jessie2015, on=[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Jessie ends up appearing four times.\n",
    "\n",
    "- Female Jessies from 1995 are matched with female Jessies from 2015. (Good!)\n",
    "- Male Jessies from 1995 are matched with male Jessies from 2015. (Good!)\n",
    "- Female Jessies from 1995 are matched with male Jessies from 2015. (Huh?)\n",
    "- Male Jessies from 1995 are matched with female Jessies from 2015. (Huh?)\n",
    "\n",
    "The problem is that there were multiple Jessies in the 1995 data and multiple Jessies in the 2015 data. We say that these two data sets have a **many-to-many relationship**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Data\n",
    "\n",
    "In the previous section, we discussed how to _merge_ (or _join_) two data sets by matching on certain variables. But what happens when no match can be found for a row in one `DataFrame`? \n",
    "\n",
    "First, let's determine how _pandas_ handles this situation by default. The name \"Nevaeh\", which is \"Heaven\" spelled backwards, is said to have taken off when Sonny Sandoval of the band P.O.D. gave his daughter the name in 2000. Let's look at how common this name was four years earlier and four years after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1996 = pd.read_csv(\"./data/names/yob1996.txt\",\n",
    "                        header=None,\n",
    "                        names=[\"Name\", \"Sex\", \"Count\"])\n",
    "names2004 = pd.read_csv(\"./data/names/yob2004.txt\",\n",
    "                        header=None,\n",
    "                        names=[\"Name\", \"Sex\", \"Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1996[names1996.Name == \"Nevaeh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names2004[names2004.Name == \"Nevaeh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1996, there were no girls (or fewer than 5) named Nevaeh; just eight years later, there were over 3000 girls (and 27 boys) with the name. It seems like Sonny Sandoval had a huge effect.\n",
    "\n",
    "What will happen to the name \"Nevaeh\" when we merge the two data sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = names1996.merge(names2004, on=[\"Name\", \"Sex\"], suffixes=(\"1996\", \"2004\"))\n",
    "names[names.Name == \"Nevaeh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, _pandas_ only includes combinations that are present in _both_ `DataFrame`s. If it cannot find a match for a row in one `DataFrame`, then the combination is simply dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in this context, the fact that a name does not appear in one data set is informative. It means that no babies were born in that year with that name. (Technically, it means that fewer than 5 babies were born with that name, as any name that was assigned fewer than 5 times is omitted for privacy reasons.) We might want to include names that appeared in only one of the two `DataFrame`s, rather than just the names that appeared in both. \n",
    "\n",
    "There are four types of joins, distinguished by whether they include names from the left `DataFrame`, the right `DataFrame`, both, or neither:\n",
    "\n",
    "1. **inner join** (default): only values that are present in _both_ `DataFrame`s are included in the result\n",
    "2. **outer join**: any value that appears in _either_ `DataFrame` is included in the result\n",
    "3. **left join**: any value that appears in the _left_ `DataFrame` is included in the result, whether or not it appears in the right `DataFrame`\n",
    "4. **right join**: any value that appears in the _right_ `DataFrame` is included in the result, whether or not it appears in the left `DataFrame`.\n",
    "\n",
    "In _pandas_, the join type is specified using the `how=` argument.\n",
    "\n",
    "Now let's look at examples of each of these types of joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "names_inner = names1996.merge(names2004, on=[\"Name\", \"Sex\"], how=\"inner\", suffixes=(\"1996\", \"2004\"))\n",
    "names_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "names_outer = names1996.merge(names2004, on=[\"Name\", \"Sex\"], how=\"outer\", suffixes=(\"1996\", \"2004\"))\n",
    "names_outer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names like \"Zyrell\" and \"Zyron\" appeared in the 2004 data but not the 1996 data. For this reason, their count in 1996 is `NaN`. In general, there will be `NaN`s in a `DataFrame` resulting from an outer join. Any time a name appears in one `DataFrame` but not the other, there will be `NaN`s in the columns from the `DataFrame` whose data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_outer.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, there are no `NaN`s when we do an inner join. That is because we restrict to only the (name, sex) pairs that appeared in both `DataFrame`s, so we have counts for both 1996 and 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_inner.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left and right joins preserve data from one `DataFrame` but not the other. For example, if we were trying to calculate the percentage change for each name from 1996 to 2004, we would want to include all of the names that appeared in the 1996 data. If the name did not appear in the 2004 data, then that is informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join\n",
    "names_left = names1996.merge(names2004, on=[\"Name\", \"Sex\"], how=\"left\", suffixes=(\"1996\", \"2004\"))\n",
    "names_left.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a left join has `NaN`s in the column from the right `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_left.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a right join, on the other hand, has `NaN`s in the column from the left `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join\n",
    "names_right = names1996.merge(names2004, on=[\"Name\", \"Sex\"], how=\"right\", suffixes=(\"1996\", \"2004\"))\n",
    "names_right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_right.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to visualize the different types of joins is using Venn diagrams. The shaded circles specify which values are included in the output.\n",
    "\n",
    "![](./images/joins.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Make a line plot showing the popularity of your name over the years.  Make sure you include all the years in the dataset!  You'll need to write some code to make sure you open **all** the year datafiles.\n",
    "\n",
    "(**Optional Extra Credit (2 points)**: As an added challenge, try marking the year you were born with a graphic element.)\n",
    "\n",
    "(If you have a rare name that does not appear in the data set, choose a friend's name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 2-4 deal with the [Movielens data 1M Dataset](https://grouplens.org/datasets/movielens/1m/) which has been copied into the Github for this class.  This dataset is a collection of movie ratings submitted by users. The information about the movies, ratings, and users are stored in three separate files, called `movies.dat`, `ratings.dat`, and `users.dat`. The column names are not included with the data files. Refer to the data documentation (`./data/movielens/README`) for the column names and how the columns correspond across the data sets.\n",
    "\n",
    "For the first part of this excersize you need to open these datafiles, make sure the column headders are correct, and merge them into a single DataFrame to answer the questions.  Take note of the seperators in the data and maybe look at the documentation for [Pandas read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) for some hits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Who's more generous with ratings: males or females? Calculate the average of the ratings given by male users, and the average of the ratings given by female users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Calculate the number of ratings for each of the movies. How many of the movies had zero ratings?\n",
    "\n",
    "(_Hint_: You may need to use operations on the ratings table first.)\n",
    "\n",
    "(_Hint_: Why is an inner join not sufficient here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** How many movies received both a 1 and a 5 rating? Do this by creating and joining two appropriate tables.\n",
    "\n",
    "(*Hint:* The [Pandas unique()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) function may be nice here...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.** Among movies with at least 100 ratings, which movie had the highest average rating? \n",
    "\n",
    "(**Hint:** Try filtering the dataframe before using other commands.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS BONUS 8 POINTS.** For each movie, calculate the average age of the users who rated it and the average rating. Make a scatterplot showing the relationship between age and rating, with each point representing a movie. Use the size of each point to represent the number of users who rated the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you have filled out all the questions, submit via [Tulane Canvas](https://tulane.instructure.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
